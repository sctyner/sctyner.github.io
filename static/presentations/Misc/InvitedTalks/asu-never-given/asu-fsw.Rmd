---
title: "Statistical Minds:"
subtitle: "How thinking like a statistician<br>can make you a better forensic scientist"
author: "Dr. Sam Tyner<br>Iowa State University, CSAFE"
date: "October 11, 2018"
output:
  xaringan::moon_reader:
    css: ["default", "default-fonts", "css/asu-fsw.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE)
```

```{r pkgs}
library(ggplot2)
```

class: quote

> # "There are three kinds of lies..." 

--

- #### lies 

--

- ### damned lies

--

- ## statistics

---
# "Statistics" 

What do you hear?

--

.pull-left[

No formal experience: 

- math
- data
- numbers
- sports

]

--

.pull-right[

Took one or two stats classes:

- model 
- hypothesis test
- $p$-value
- confusing

]

--

.img-center[

<img src="https://media.giphy.com/media/3owzW5c1tPq63MPmWk/giphy.gif?cid=3640f6095babc7a3373061442e6452c5"/>

]

--

You probably know more than you think you do! 

---
# Does this look familiar? 

```{r bellcurve, echo=FALSE, fig.align='center', fig.height=4, fig.width=9}
x <- seq(52, 76, .1)
y <- dnorm(x, mean = 64, sd = 3)
qplot(x=x,y=y,geom='line', size = I(3), color = I("blue"), lineend = "round") + theme_void() 
```

--

"bell curve" aka the **normal distribution** 

---
# The Normal Distribution

- Used to describe variability in a population

--

- Characterized by 2 parameters: 

--

- First, the *mean* value ( $\mu$ ) (aka *average* aka *expected value*): the "best guess" for the population

--

- Second, the *standard deviation* ( $\sigma$ ) (or *variance* which is equal to $\sigma^2$): the average distance an observation is from the average

--


For example: 

In the US, women's heights follow a normal distribution with mean 64in (5'4") and standard deviation 3in. (For women aged 20+. [Source.](https://www.cdc.gov/nchs/data/series/sr_03/sr03_039.pdf))

--

- Pick a woman at random: best guess, she's 5'4", but wouldn't be surprised if she was as short as 5'1" or as tall as 5'7"

---
# What is statistics?

--

- **Statistics**: "the study of how best to collect, analyze, and draw conclusions from data" (from a textbook)

--

- **Statistics**: "a branch of mathematics dealing with the collection, classification, analysis, interpretation of numerical facts, for drawing inferences on the basis of their quantifiable likelihood (probability) of data." (from [Wikipedia](https://en.wikipedia.org/wiki/Statistics))

--

- **Statistics**: "the study of uncertainty" (my definition)

---
# Uncertainty

What is the average height of women in the US aged 20 years & over? 

--

- Trick question (Sorry!)

--

There is NO WAY to know the true answer to this question. (Why?)

--

**Ground truth**: the (usually un-knowable) facts of a population, case, etc. 

--

Unless we construct it (i.e. for an experiment), we can **never** be 100% certain about ground truth

---
# Uncertainty in forensic science

--

- How many striae to we need to be 100% certain a bullet found at the crime scene came from a suspect's gun? 

--

- How can we be sure that the fingerprint found at the crime scene in the zoo came from a human and not a [koala](https://io9.gizmodo.com/5798400/koalas-have-exactly-the-same-fingerprints-as-humans)?

--

- Can we match a bullet to a gun after the gun has been fired 3,000 times? 

--

- How common is the pair of shoes that left the bloody shoeprint at the crime scene? 

---
# How can statistics help? 

1. Data collection for population inference
    - Your conclusion is only as good as your data. 
2. Experimental design
    - Control the sources variability to determine causation
3. Modeling
    - What existing relationships can we account for so we can get closer to the truth (with less uncertainty)? 
4. Hypothesis tests
    - Make a conclusion and quantify your uncertainty
    
These are all built on top of each other: 

.img-center[

<img src="img/statpyramid.png" height="200px"/>

]



---
class: center, middle, inverse
# Data collection for population inference

---
# Population vs. Sample

To learn about a population: 

- take a sample from the population
- collect data from the sample
- make inference (educated guess) about the population based on the data in the sample 

--

Carefully control how we make inference in order to minimize and quantify uncertainty. 

--

Not just any sample will do! 

---
# Good samples 

Good samples are: 

- **Large**: "rule of thumb" is greater than 30, but depends on size of population, resources, etc. 
- **Representative**: every type of unit in the population that matters is represented in the sample, and each type is represented in proportion to how common it is in the population 
- **Random**: every unit in the population should have an equal opportunity to be included in the sample 

---
# Bad samples 

Bad samples are: 

- **Small**: they don't capture enough of the variation in the population at large.
- **Unrepresentative**: some group is over- or under-represented in the sample e.g. including Jeff Bezos in a sample to learn about average salary in the U.S. 
- **Biased**: the way the sample is selected favors one type of observation over others. e.g. Asking people, "How much do you spend on groceries?" outside of a Wal-Mart vs. a Whole Foods

---
# Bring Data 

> ### "In God we trust; all others bring data." - W. Edwards Deming, PhD 

Your conclusions are only as good as the data you used to make them. 

- Example: making a firearm identification on "only 3 consecutive matching striae" on a bullet
- Really??? What do the data say? 

--

.img-center[

  <img src="img/csm.png" width="50%"/>

]

---
# Oh, the humanity! 

- forensic scientists form conclusions based on training and experience
- human memories are imperfect & biased 
- human brains are not as accurate as computers at recalling information
- humans make mistakes 

Save yourself time, energy, and stress by learning from the data! 

--

.img-center[

  <img src="img/csm.png" width="50%"/>

]


---
class: center, middle, inverse
# Modeling

---
# Variables 

Reduce uncertainty with a *model*

- dependent variable: what you want to learn about
- explanatory variable: something that might *explain* changes in the dependent variable

--

For example: 

If we wanted to learn about *weight* of adults in the U.S. (our dependent variable), what *explanatory variable* should we use? 

--

- Height 

---
# Good models

**Good models** explain as much of the uncertainty in the dependent variable as possible while:
  * remaining general & broadly applicable 
  * allowing for some small, controlled amount of uncertainty
  
--

i.e. If I take a sample from the same population, the model I built on the old sample should get close to the new data, but it won't ever be perfect. 

---
# Bad models

**Bad models** usually fall into one or more of these categories: 
  * overfit: they work really well for the sample data, but not for similar data from the population
  * uninterpretable: they are so complicated that we can't really tell what's going on with the data 
  * ignore lurking variables: lurking variables aren't in the model but probably explain both the explanatory & dependent variables.

.img-center[

![](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1729/2017/04/15031843/m3_examining_relationships_topic_3_1_scatter_linear_corr_causation2.gif)

]

---
class: center, middle, inverse
# Experimental Design

---
# Causation

Correlation $\neq$ causation

Causation can only be established with a well-designed experiment 

---
class: center, middle, inverse
# Hypothesis tests

---
# Need to talk about

- uncertainty: error rates (false positive, false negative)
- structure of hypotheses (prosecution, defense)
- proposition level 


---
# Keep in mind<sup>1</sup>

.img-center[

<img src="img/knowns.png", height="400px"/>

]

.footnote[
[1] Thanks, Donald Rumsfeld.
]

---
# Conclusion

- Thinking like a statistician means thinking about uncertainty 

- Ask yourself: 
    * What do I know for sure? 
    * How do I know that? 
    * What don't I know? 
    * How can I answer my questions?  
    * Can I quantify what I don't know? 

--

- You need to be honest about what you don't know:
    * You need to know what you don't know, and you need to communicate that.
    * "I don't know" is better than a weak guess based on little to no data
    * 45% of wrongful convictions found by the Innocence Project were due (at least in part) by some misuse of forensic science
    * Source: [innocenceproject.org/causes/misapplication-forensic-science](https://www.innocenceproject.org/causes/misapplication-forensic-science/)

--

- Honesty and awareness about uncertainty can lead to 
    * better outcomes
    * more justice
    * forensic scientists with less stress 
    
    
---
class: quote

> ## "Information...is not dangerous in itself. The question is: How do you choose to use it? You can grab a knife to chop your garlic or to slit someone's throat; it is *you* who gives the knife its character." - *Linda Bacon, PhD*